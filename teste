import streamlit as st
import time
from langchain.chat_models import AzureChatOpenAI
from langchain.schema import HumanMessage
from prompts import PROMPTS

# Configuração da chave da OpenAI na barra lateral
with st.sidebar:
    azure_api_key = st.text_input("Azure OpenAI API Key", key="chatbot_api_key", type="password")
    azure_endpoint = st.text_input("Azure OpenAI Endpoint", key="chatbot_endpoint")
    deployment_name = st.text_input("Azure Deployment Name", key="chatbot_deployment")
    "[Get an Azure OpenAI API key](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource)"

# Exibir título e descrição do assistente
st.title("✍️ Story Creator")
st.write("Aqui você pode conversar sobre épicos, histórias e tarefas!")

# Inicializar o histórico específico do assistente no session_state
ASSISTANT_ID = "epic_story_task"  # ID único para o assistente
selected_prompt = PROMPTS[ASSISTANT_ID]  # Prompt selecionado

if ASSISTANT_ID not in st.session_state:
    st.session_state[ASSISTANT_ID] = [
        {"role": "system", "content": selected_prompt},
        {"role": "assistant", "content": "No que posso te ajudar?"}
    ]

# Exibir mensagens anteriores (exceto a system message)
for msg in st.session_state[ASSISTANT_ID]:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

# Input do usuário
user_input = st.chat_input("Digite sua pergunta ou solicitação:")

if user_input:
    if not azure_api_key or not azure_endpoint or not deployment_name:
        st.info("⚠️ Insira sua chave da Azure OpenAI, endpoint e deployment name para continuar.")
        st.stop()

    # Adicionar a pergunta do usuário ao histórico
    st.session_state[ASSISTANT_ID].append({"role": "user", "content": user_input})
    st.chat_message("user").write(user_input)

    # Criar cliente da Azure OpenAI
    llm = AzureChatOpenAI(
        openai_api_key=azure_api_key,
        openai_api_base=azure_endpoint,
        deployment_name=deployment_name,
        openai_api_version="2023-05-15"
    )

    # Converter histórico para formato do Langchain
    messages = [HumanMessage(content=msg["content"]) for msg in st.session_state[ASSISTANT_ID] if msg["role"] != "system"]

    # Obter resposta do modelo
    response = llm.invoke(messages)
    msg = response.content

    # Adicionar a resposta do assistente ao histórico
    st.session_state[ASSISTANT_ID].append({"role": "assistant", "content": msg})

    # Exibir a resposta gradualmente
    with st.chat_message("assistant"):
        response_container = st.empty()  # Placeholder para a resposta
        displayed_text = ""

        for char in msg:  # Exibição gradual caractere por caractere
            displayed_text += char
            response_container.write(displayed_text)  # Atualiza o texto dinamicamente
            time.sleep(0.02)  # Pequeno delay para simular digitação